{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## EX4\n",
    "`Author:    Hongru He`<br>\n",
    "`Date:      01/23/2026`"
   ],
   "id": "a7cd1291c757ae44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Setting Notice\n",
    "1. Make sure you put the dataset folders under the same folder with this notebook.\n",
    "2. Make sure adjust the value of `BASE_DIR` based on the exact path of your base directory\n",
    "3. Make sure the dataset folders' names are consistent with those in `ham_dirs` and `spam_dirs` in the function `load_emails_from_dir`"
   ],
   "id": "46bb8ee74ee7f8ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dataset Selection Reasoning\n",
    "The 2003 (20030228) SpamAssassin dataset was chosen because it provides a clean, self-contained snapshot that includes both spam and non-spam emails, allowing for a balanced and consistent binary classification setup. The 2002 datasets were excluded as they are older and less thoroughly cleaned, while the 2005 data was not used because it contains only spam messages and no corresponding ham, which would introduce class imbalance and temporal mismatch. Using only the 2003 dataset avoids data leakage and ensures fair, interpretable evaluation results."
   ],
   "id": "2f99ddf6b44f10b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Load emails and assign labels",
   "id": "610cb506fa86de10"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-24T03:00:59.448884Z",
     "start_time": "2026-01-24T03:00:55.081852Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "BASE_DIR = \"/Users/hhe/Desktop/Academia/MSCS/CPSC5310/EXs/EX4\"      # Change this based on the exact path of base directory\n",
    "\n",
    "def load_emails_from_dir(dir_path, label):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        # Skip hidden files like .DS_Store\n",
    "        if filename.startswith('.'):\n",
    "            continue\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        with open(file_path, \"r\", encoding=\"latin-1\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "ham_dirs = [\n",
    "    \"easy_ham\",\n",
    "    \"easy_ham_2\",\n",
    "    \"hard_ham\",\n",
    "]\n",
    "spam_dirs = [\n",
    "    \"spam\",\n",
    "    \"spam_2\",\n",
    "]\n",
    "\n",
    "X_texts = []\n",
    "y_labels = []\n",
    "\n",
    "# Ham = 0, Spam = 1\n",
    "for d in ham_dirs:\n",
    "    texts, labels = load_emails_from_dir(os.path.join(BASE_DIR, d), label=0)\n",
    "    X_texts.extend(texts)\n",
    "    y_labels.extend(labels)\n",
    "\n",
    "for d in spam_dirs:\n",
    "    texts, labels = load_emails_from_dir(os.path.join(BASE_DIR, d), label=1)\n",
    "    X_texts.extend(texts)\n",
    "    y_labels.extend(labels)\n",
    "\n",
    "X_texts = np.array(X_texts)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "print(\"Total emails:\", len(X_texts))\n",
    "print(\"Spam ratio:\", y_labels.mean())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails: 6052\n",
      "Spam ratio: 0.31378056840713814\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:01:23.412803Z",
     "start_time": "2026-01-24T03:01:21.639821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emails_df = pd.DataFrame({\"text\": X_texts, \"label\": y_labels})\n",
    "emails_df.head()"
   ],
   "id": "358d600ae0438941",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  From fork-admin@xent.com  Tue Sep 24 17:55:30 ...      0\n",
       "1  From rpm-list-admin@freshrpms.net  Mon Sep  9 ...      0\n",
       "2  From secprog-return-625-jm=jmason.org@security...      0\n",
       "3  Return-Path: nas@python.ca\\nDelivery-Date: Thu...      0\n",
       "4  From fork-admin@xent.com  Thu Aug 29 11:03:51 ...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From fork-admin@xent.com  Tue Sep 24 17:55:30 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From rpm-list-admin@freshrpms.net  Mon Sep  9 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From secprog-return-625-jm=jmason.org@security...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return-Path: nas@python.ca\\nDelivery-Date: Thu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From fork-admin@xent.com  Thu Aug 29 11:03:51 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Split train/test datasets",
   "id": "3fb4d8c00ae79e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:03:15.295862Z",
     "start_time": "2026-01-24T03:03:13.220022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_texts,\n",
    "    y_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_labels,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))\n",
    "print(\"Train spam ratio:\", y_train.mean(), \"Test spam ratio:\", y_test.mean())"
   ],
   "id": "fd3366ffdba58f0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4841 Test size: 1211\n",
      "Train spam ratio: 0.3137781450113613 Test spam ratio: 0.3137902559867878\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Text cleaning and vectorization",
   "id": "425b29e3a76a3237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:05:57.124458Z",
     "start_time": "2026-01-24T03:05:57.105401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "URL_RE = re.compile(r\"(http|https)://\\S+|www\\.\\S+\")\n",
    "NUM_RE = re.compile(r\"\\d+\")\n",
    "\n",
    "def simple_preprocess(text):\n",
    "    # 1. lower-case\n",
    "    text = text.lower()\n",
    "    # 2. replace URLs and numbers\n",
    "    text = URL_RE.sub(\" URL \", text)\n",
    "    text = NUM_RE.sub(\" NUMBER \", text)\n",
    "    # 3. keep only letters and a few separators\n",
    "    text = re.sub(r\"[^a-z]+\", \" \", text)\n",
    "    return text"
   ],
   "id": "86f43445cb6eba12",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Pipeline with Logistic Regression",
   "id": "3b781ebe6956cf8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:06:06.937453Z",
     "start_time": "2026-01-24T03:05:59.958741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "binary_vectorizer = CountVectorizer(\n",
    "    preprocessor=simple_preprocess,\n",
    "    binary=True,          # presence/absence\n",
    "    min_df=2,             # ignore very rare words\n",
    ")\n",
    "\n",
    "log_reg_clf = Pipeline([\n",
    "    (\"vect\", binary_vectorizer),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "    )),\n",
    "])\n",
    "\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"ham\", \"spam\"]))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "ac7c950c5d1a7fe0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       831\n",
      "        spam       0.98      0.97      0.98       380\n",
      "\n",
      "    accuracy                           0.99      1211\n",
      "   macro avg       0.98      0.98      0.98      1211\n",
      "weighted avg       0.99      0.99      0.99      1211\n",
      "\n",
      "[[824   7]\n",
      " [ 10 370]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Multiple classifiers\n",
    "#### Multinomial Naive Bayes"
   ],
   "id": "92bb709ed8888a70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:07:18.471121Z",
     "start_time": "2026-01-24T03:07:13.053105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    preprocessor=simple_preprocess,\n",
    "    binary=False,   # use counts\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "nb_clf = Pipeline([\n",
    "    (\"vect\", count_vectorizer),\n",
    "    (\"clf\", MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "print(\"=== MultinomialNB ===\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=[\"ham\", \"spam\"]))\n",
    "print(confusion_matrix(y_test, y_pred_nb))"
   ],
   "id": "7270db13b429ec97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.96      0.95       831\n",
      "        spam       0.92      0.88      0.90       380\n",
      "\n",
      "    accuracy                           0.94      1211\n",
      "   macro avg       0.93      0.92      0.93      1211\n",
      "weighted avg       0.94      0.94      0.94      1211\n",
      "\n",
      "[[800  31]\n",
      " [ 46 334]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Linear SVM",
   "id": "d595ec487547f83a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T03:07:43.023131Z",
     "start_time": "2026-01-24T03:07:37.530724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "svm_vectorizer = CountVectorizer(\n",
    "    preprocessor=simple_preprocess,\n",
    "    binary=True,\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    (\"vect\", svm_vectorizer),\n",
    "    (\"clf\", LinearSVC()),\n",
    "])\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"=== LinearSVC ===\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=[\"ham\", \"spam\"]))\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ],
   "id": "2458e77e18cfb4a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LinearSVC ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       831\n",
      "        spam       0.99      0.98      0.98       380\n",
      "\n",
      "    accuracy                           0.99      1211\n",
      "   macro avg       0.99      0.99      0.99      1211\n",
      "weighted avg       0.99      0.99      0.99      1211\n",
      "\n",
      "[[826   5]\n",
      " [  9 371]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary of Findings\n",
    "Using the Apache SpamAssassin 2003 corpus, I trained and evaluated several machine learning models for spam classification. The dataset contained 6,052 emails with a spam ratio of approximately 31%, and a stratified 80/20 train–test split preserved this distribution across both sets.\n",
    "\n",
    "All models benefited from basic text preprocessing and bag-of-words feature representations, but their performance varied noticeably. Multinomial Naive Bayes served as a reasonable baseline, achieving 94% overall accuracy. However, it produced a higher number of misclassifications, particularly false negatives, resulting in lower spam recall (0.88). This behavior is consistent with Naive Bayes’ strong independence assumptions, which are often violated in real email text.\n",
    "\n",
    "Linear models performed substantially better. Logistic Regression achieved near-perfect performance, with spam precision of 0.98 and spam recall of 0.97, indicating a strong balance between minimizing false positives and false negatives. The Linear Support Vector Machine (LinearSVC) achieved the best overall results, with spam precision of 0.99 and spam recall of 0.98, and the fewest total errors on the test set.\n",
    "\n",
    "Overall, the results show that simple bag-of-words features combined with linear classifiers are highly effective for spam detection. In particular, using binary word-presence features proved sufficient to separate spam from ham with very high accuracy. While these results are likely optimistic compared to real-world email filtering due to the curated nature of the dataset, they clearly demonstrate the effectiveness of linear text classifiers and the importance of feature representation in supervised learning tasks."
   ],
   "id": "638fe1e6cad58cfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
